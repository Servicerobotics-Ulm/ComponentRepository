//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain
// The SmartSoft Toolchain has been developed by:
//  
// Service Robotics Research Center
// University of Applied Sciences Ulm
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// www.servicerobotik-ulm.de
//
// This file is generated once. Modify this file to your needs. 
// If you want the toolchain to re-generate this file, please 
// delete it before running the code generator.
//--------------------------------------------------------------------------


//--------------------------------------------------------------------------
//BSD 3-Clause License
//
//  Copyright (C) Servicerobotics Ulm
//  University of Applied Sciences Ulm
//  Prittwitzstr. 10
//  89075 Ulm
//  Germany
//  All rights reserved.
//
//  Author: Nayabrasul Shaik
//
//Redistribution and use in source and binary forms, with or without
//modification, are permitted provided that the following conditions are met:
//
//* Redistributions of source code must retain the above copyright notice, this
//  list of conditions and the following disclaimer.
//
//* Redistributions in binary form must reproduce the above copyright notice,
//  this list of conditions and the following disclaimer in the documentation
//  and/or other materials provided with the distribution.
//
//* Neither the name of the copyright holder nor the names of its
//  contributors may be used to endorse or promote products derived from
//  this software without specific prior written permission.
//
//THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
//AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
//IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
//DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
//FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
//DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
//SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
//CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
//OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
//OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#include "LivePreviewTask.hh"
#include "ComponentHandEyeCalibration.hh"
#include <armadillo.hh>
#include <EulerTransformationMatrices.hh>
#include <iostream>
#include <vector>
#include <opencv2/calib3d.hpp>
#include <opencv2/core/utils/filesystem.hpp>

using namespace cv;
LivePreviewTask::LivePreviewTask(SmartACE::SmartComponent *comp) 
:	LivePreviewTaskCore(comp)
{
	std::cout << "constructor LivePreviewTask\n";
	image_counter = 0;
	init = false;
	cv::namedWindow("Live view", cv::WINDOW_NORMAL);

	//calibration directory
	std::ostringstream oss;
	std::chrono::system_clock::time_point now = std::chrono::system_clock::now();
	std::time_t now_c = std::chrono::system_clock::to_time_t(now);
	oss<<"/tmp/calibration_data_" <<std::put_time(std::localtime(&now_c), "%d_%m_%Y_%H_%M_%S");
	data_dir = cv::String(oss.str());
	cv::utils::fs::createDirectory(data_dir);


	//log_file name
	std::string filename;
	oss.str("");
	oss.clear();
	oss<<data_dir<<"/handeye_calib_log_" <<std::put_time(std::localtime(&now_c), "%d_%m_%Y_%H_%M_%S")<<".yml";
	filename = oss.str();
	//open log file
	log_file.open(filename.c_str(), cv::FileStorage::WRITE);
	std::cout << "logfile is opened : " << filename << std::endl;
}
LivePreviewTask::~LivePreviewTask() 
{
	std::cout << "destructor LivePreviewTask\n";
}



int LivePreviewTask::on_entry()
{
	if(COMP->getGlobalState().getCalibration().getType() == ParameterStateStruct::CalibrationType::typeType::HAND_IN_EYE)
	{
		calibration_type = CalibrationType::HAND_IN_EYE;
	}else{
		calibration_type = CalibrationType::HAND_TO_EYE;
	}
	charuco_board.size.height = COMP->getParameters().getChArUcoBoard().getRows();
	charuco_board.size.width = COMP->getParameters().getChArUcoBoard().getColumns();
	charuco_board.square_length = COMP->getParameters().getChArUcoBoard().getSquareLength();
	charuco_board.marker_length = COMP->getParameters().getChArUcoBoard().getMarkerLength();
	charuco_board.dictionary = get_dictionary_type(COMP->getParameters().getChArUcoBoard().getDictionaryType());
	for (uint8_t i = 0; i < charuco_board.size.height; i++) {
		for (uint8_t j = 0; j < charuco_board.size.width; j++) {

			charuco_board.points_3d.push_back(cv::Point3d(i*charuco_board.square_length, j*charuco_board.square_length,0));
		}
	}
	return 0;
}
int LivePreviewTask::on_execute()
{
	Smart::StatusCode status;
	DomainVision::CommVideoImage comm_rgb_image;
	cv::Mat t2c_rotation_vector, t2c_translation_matrix;


	status = COMP->rGBImagePushServiceIn->getUpdateWait(comm_rgb_image);
	if(status == Smart::SMART_OK && comm_rgb_image.getIs_valid())
	{
		if(!init)
		{
			get_camera_matrix_nd_distortion_coeffs(comm_rgb_image, camera_matrix, distortion_coeffs);
			log_file << "camera_matrix" << camera_matrix;
			log_file << "distortion_coeffs" << distortion_coeffs;
			init = true;
		}

		cv::Mat bgr_mat;
		CommVideoImage2CVMat(comm_rgb_image, bgr_mat);

		cv::Mat bgr_mat_original = bgr_mat.clone();

		//returns pose of checker board origin in camera frame
		detect_charuco_board_corners_3d(bgr_mat, charuco_board, t2c_rotation_vector, t2c_translation_matrix);

		cv::Mat resized_bgr;
		cv::resize(bgr_mat, resized_bgr, cv::Size(bgr_mat.rows, bgr_mat.cols/4));
		imshow("Live view", resized_bgr);
		int key = cv::waitKey();

		//press 'y' or 'Y' to accept the current image
		if(key == 89 || key == 121)
		{
			// gripper2base = tcp pose in arm base frame
			// base2gripper = arm base pose in gripper frame
			cv::Mat g2b_translation_matrix;
			cv::Mat g2b_rotation_matrix;
			if(!get_gripper2base_pose(g2b_rotation_matrix, g2b_translation_matrix))
			{
				return 0;
			}

			R_gripper2base.push_back(g2b_rotation_matrix);
			t_gripper2base.push_back(g2b_translation_matrix);

			cv::Mat TF_gripper2base;
			to_homogeneous_tf_matrix(g2b_rotation_matrix, g2b_translation_matrix, TF_gripper2base);

			log_file <<"R_gripper2base"+std::to_string(image_counter)<< g2b_rotation_matrix;
			log_file <<"t_gripper2base"+std::to_string(image_counter)<< g2b_translation_matrix;
			log_file <<"H_gripper2base"+std::to_string(image_counter)<< TF_gripper2base;

			//calculate arm base pose in gripper frame, this is required for hand to eye calibration
			cv::Mat TF_base2gripper;
			cv::invert(TF_gripper2base, TF_base2gripper);

			cv::Mat b2g_translation_matrix;
			cv::Mat b2g_rotational_matrix;
			rmat_from_homogeneous_tf_matrix(TF_base2gripper, b2g_rotational_matrix);
			tmat_from_homogeneous_tf_matrix(TF_base2gripper, b2g_translation_matrix);

			R_base2gripper.push_back(b2g_rotational_matrix);
			t_base2gripper.push_back(b2g_translation_matrix);

			log_file << "R_base2gripper"+std::to_string(image_counter)<< b2g_rotational_matrix;
			log_file << "t_base2gripper"+std::to_string(image_counter)<< b2g_translation_matrix;


			//save target2cam pose i.e target pose in camera frame
			cv::Mat t2c_rotation_matrix;
			cv::Rodrigues(t2c_rotation_vector,t2c_rotation_matrix);

			cv::Mat TF_target2cam; // target pose in camera frame
			to_homogeneous_tf_matrix(t2c_rotation_matrix, t2c_translation_matrix, TF_target2cam);

			log_file << "R_target2cam"+std::to_string(image_counter)<< t2c_rotation_matrix;
			log_file << "t_target2cam"+std::to_string(image_counter)<< t2c_translation_matrix;
			log_file << "H_target2cam"+std::to_string(image_counter)<< TF_target2cam;

			R_target2cam.push_back(t2c_rotation_matrix);
			t_target2cam.push_back(t2c_translation_matrix);


			//save the current image original and drawing
			std::ostringstream org_file;
			org_file<< data_dir<<"/"
					<< std::setfill('0')<<std::setw(5)<<image_counter
					<<".png";
			std::string org_filename = org_file.str();
			cv::imwrite(org_filename, bgr_mat_original);

			std::ostringstream drawn_file;
			drawn_file<< data_dir<<"/"
					<< std::setfill('0')<<std::setw(5)<<image_counter
					<<"_drawn.png";
			std::string drawn_filename = drawn_file.str();
			cv::imwrite(drawn_filename, bgr_mat);
			++image_counter;

		}

		//press 'c' or 'C' to start calibration.
		else if(key == 67 || key == 99)
		{
			calibrate();
		}
	}

	return 0;
}
int LivePreviewTask::on_exit()
{
	log_file.release();
	return 0;
}

void LivePreviewTask::to_homogeneous_tf_matrix(const cv::Mat& rotation_matrix, const cv::Mat& translation_matrix, cv::Mat& homogeneous_mat)
{
	homogeneous_mat = cv::Mat(4,4,CV_64FC1, 0.0);

	rotation_matrix.copyTo(homogeneous_mat(cv::Rect(0,0,3,3)));

	translation_matrix.copyTo(homogeneous_mat(cv::Rect(3,0,1,3)));

	homogeneous_mat.at<double>(3,3) = 1.0;
}
void LivePreviewTask::rmat_from_homogeneous_tf_matrix(const cv::Mat homogeneous_mat, cv::Mat& rotation_matrix)
{
	rotation_matrix = homogeneous_mat(cv::Rect(0,0,3,3));
}
void LivePreviewTask::tmat_from_homogeneous_tf_matrix(const cv::Mat homogeneous_mat, cv::Mat& translation_matrix)
{
	translation_matrix = homogeneous_mat(cv::Rect(3,0,1,3));
}
void LivePreviewTask::get_camera_matrix_nd_distortion_coeffs(DomainVision::CommVideoImage& comm_rgb_image, cv::Mat& camera_matrix, cv::Mat& distortion_coeffs)
{
	arma::mat comm_color_intrinsic;
	comm_color_intrinsic.zeros();
	comm_color_intrinsic = comm_rgb_image.get_intrinsic();
	std::vector<double>color_intrinsics = comm_rgb_image.getIntrinsic_mCopy();

	std::cout << "rgb_intrinsics : " << std::endl;
	std::copy(color_intrinsics.begin(), color_intrinsics.end(), std::ostream_iterator<double>(std::cout, ","));
	std::cout << " : " << std::endl;

	double fx = comm_color_intrinsic(0,0);
	double fy = comm_color_intrinsic(1,1);
	double cx = comm_color_intrinsic(0,2);
	double cy = comm_color_intrinsic(1,2);

	camera_matrix = cv::Mat(3,3,CV_64FC1, 0.0);
	camera_matrix.at<double>(0, 0) = 1073.045725757607;
	camera_matrix.at<double>(1, 1) = 1065.318331830934;
	camera_matrix.at<double>(0, 2) = 971.104812146685;
	camera_matrix.at<double>(1, 2) = 550.6419377461037;
	camera_matrix.at<double>(2, 2) = 1.0;

	//	camera_matrix.at<double>(0, 0) = fx;
	//	camera_matrix.at<double>(1, 1) = fy;
	//	camera_matrix.at<double>(0, 2) = cx;
	//	camera_matrix.at<double>(1, 2) = cy;
	//	camera_matrix.at<double>(2, 2) = 1.0;

	std::cout << "camera_matrix : " << camera_matrix << std::endl;

	arma::mat comm_color_distortion = arma::zeros(1,5);
	comm_color_distortion = comm_rgb_image.get_distortion();
	distortion_coeffs = cv::Mat(1,5,CV_64FC1);

	distortion_coeffs.at<double>(0,0) = comm_color_distortion(0,0);
	distortion_coeffs.at<double>(0,1) = comm_color_distortion(0,1);
	distortion_coeffs.at<double>(0,2) = comm_color_distortion(0,2);
	distortion_coeffs.at<double>(0,3) = comm_color_distortion(0,3);
	distortion_coeffs.at<double>(0,4) = comm_color_distortion(0,4);

	std::cout << "distortion_coeffs : " << distortion_coeffs << std::endl;

}
void LivePreviewTask::CommVideoImage2CVMat(DomainVision::CommVideoImage& comm_rgb_image, cv::Mat& bgr_mat)
{
	bgr_mat = cv::Mat(comm_rgb_image.get_height(),comm_rgb_image.get_width(), CV_8UC3);
	//convert CommVideoImage into cv::Mat
	{
		const unsigned char* imageData = comm_rgb_image.get_data();
		for (int r = 0; r < bgr_mat.rows; r++)
		{
			for (int c = 0; c < bgr_mat.cols; c++)
			{
				const unsigned char* pixel = (imageData + r * 3* bgr_mat.cols + c * 3);
				//RGB -> BGR
				bgr_mat.at<cv::Vec3b>(r,c)[0]=pixel[2];
				bgr_mat.at<cv::Vec3b>(r,c)[1]=pixel[1];
				bgr_mat.at<cv::Vec3b>(r,c)[2]=pixel[0];
			}
		}
	}
}
void LivePreviewTask::detect_charuco_board_corners_3d(const cv::Mat& bgr_mat,  ChArUcoBoard& charuco_board, cv::Mat& rotation_vector, cv::Mat& translation_matrix)
{
	cv::Size	board_size(7,9);
	std::vector<cv::Point2f> detected_corners;
	cv::Mat gray_mat;


	cv::cvtColor(bgr_mat, gray_mat, cv::COLOR_BGR2GRAY, 1);


	std::vector< int > markerIds;
	std::vector< std::vector<Point2f> > markerCorners;
	cv::Ptr<cv::aruco::Dictionary> dictionary = cv::aruco::getPredefinedDictionary(charuco_board.dictionary);
	cv::Ptr<cv::aruco::CharucoBoard> board = cv::aruco::CharucoBoard::create(charuco_board.size.width,
			charuco_board.size.height,
			charuco_board.square_length,
			charuco_board.marker_length,
			dictionary);
	cv::Ptr<cv::aruco::DetectorParameters> params = cv::aruco::DetectorParameters::create();
	params->cornerRefinementMethod = cv::aruco::CORNER_REFINE_SUBPIX;

	cv::aruco::detectMarkers(gray_mat, dictionary, markerCorners, markerIds, params);

	std::stringstream ss;

	if(markerIds.size()>0)
	{
		ss << "Checker board Found : " << std::setw(2) <<(image_counter+1)<< std::endl;


		std::vector<cv::Point2f> charucoCorners;
		std::vector<int> charucoIds;

		cv::aruco::drawDetectedMarkers(bgr_mat, markerCorners, markerIds);
		cv::aruco::interpolateCornersCharuco(markerCorners, markerIds, gray_mat, board, charucoCorners, charucoIds);


		cv::putText(bgr_mat, ss.str(), cv::Point2d(200,100), cv::FONT_ITALIC, 2, Scalar(0,255,0), 1);

		if (charucoIds.size() > 0) {
			cv::aruco::drawDetectedCornersCharuco(bgr_mat, charucoCorners, charucoIds, Scalar(0, 0, 255));
			bool valid = cv::aruco::estimatePoseCharucoBoard(charucoCorners, charucoIds, board, camera_matrix, distortion_coeffs, rotation_vector, translation_matrix);

			if (valid)
				cv::aruco::drawAxis(bgr_mat, camera_matrix, distortion_coeffs, rotation_vector, translation_matrix, 0.1f);
		}
	}
	else
	{
		ss << "Checker board not Found : " << std::endl;
		cv::putText(bgr_mat, ss.str(), cv::Point2d(200,100), cv::FONT_ITALIC, 2, Scalar(0,0,255), 1);
	}
}

bool LivePreviewTask::get_gripper2base_pose(cv::Mat& rotation_matrix, cv::Mat& translation_matrix)
{
	CommManipulatorObjects::CommMobileManipulatorState current_state;
	Smart::StatusCode status = COMP->mobileManipulatorStateServiceIn->getUpdateWait(current_state);
	if(status == Smart::SMART_OK)
	{
		CommManipulatorObjects::CommManipulatorState arm_state = current_state.getManipulator_state();

		double x, y, z, azimuth, elevation, roll;

		arm_state.get_pose_TCP_manipulator(x, y, z, azimuth, elevation, roll, 1.0);

		arma::mat gripper2base;
		gripper2base.set_size(4, 4);
		gripper2base.zeros();
		EulerTransformationMatrices::create_zyx_matrix(x, y, z, azimuth, elevation, roll, gripper2base);

		//translation matrix
		translation_matrix = cv::Mat(3,1,CV_64FC1, 0.0);
		translation_matrix.at<double>(0,0) = gripper2base(0,3);
		translation_matrix.at<double>(1,0) = gripper2base(1,3);
		translation_matrix.at<double>(2,0) = gripper2base(2,3);

		//rotation matrix
		rotation_matrix = cv::Mat(3,3,CV_64FC1, 0.0);
		rotation_matrix.at<double>(0,0) = gripper2base(0,0);
		rotation_matrix.at<double>(0,1) = gripper2base(0,1);
		rotation_matrix.at<double>(0,2) = gripper2base(0,2);

		rotation_matrix.at<double>(1,0) = gripper2base(1,0);
		rotation_matrix.at<double>(1,1) = gripper2base(1,1);
		rotation_matrix.at<double>(1,2) = gripper2base(1,2);

		rotation_matrix.at<double>(2,0) = gripper2base(2,0);
		rotation_matrix.at<double>(2,1) = gripper2base(2,1);
		rotation_matrix.at<double>(2,2) = gripper2base(2,2);

	}else{
		std::cout << "Error while getting current manipulator state: "<<Smart::StatusCodeConversion(status) << std::endl;
		return false;
	}
	return true;

}
cv::aruco::PREDEFINED_DICTIONARY_NAME LivePreviewTask::get_dictionary_type(ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType dictionary_type)
{
	switch(dictionary_type){

	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_4X4_50:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_4X4_50;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_4X4_100:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_4X4_100;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_4X4_250:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_4X4_250;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_4X4_1000:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_4X4_1000;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_5X5_50:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_5X5_50;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_5X5_100:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_5X5_100;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_5X5_250:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_5X5_250;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_5X5_1000:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_5X5_1000;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_6X6_50:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_6X6_50;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_6X6_100:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_6X6_100;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_6X6_250:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_6X6_250;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_6X6_1000:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_6X6_1000;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_7X7_50:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_7X7_50;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_7X7_100:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_7X7_100;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_7X7_250:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_7X7_250;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_7X7_1000:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_7X7_1000;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_ARUCO_ORIGINAL:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_ARUCO_ORIGINAL;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_APRILTAG_16h5:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_APRILTAG_16h5;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_APRILTAG_25h9:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_APRILTAG_25h9;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_APRILTAG_36h10:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_APRILTAG_36h10;
		break;
	case ParameterStateStruct::ChArUcoBoardType::dictionaryTypeType::DICT_APRILTAG_36h11:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_APRILTAG_36h11;
		break;
	default:
		return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_6X6_250;
		break;
	}
	return cv::aruco::PREDEFINED_DICTIONARY_NAME::DICT_6X6_250;
}
void LivePreviewTask::calibrate()
{
	std::cout << "Number of poses used : " << R_gripper2base.size() << std::endl;

	if (calibration_type == CalibrationType::HAND_TO_EYE)
	{
		std::cout << "Hand to eye Calibration : " << std::endl;

		cv::calibrateHandEye(R_base2gripper, t_base2gripper, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_TSAI);

		cv::Mat TF_cam2base;
		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_TSAI: TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_TSAI" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_base2gripper, t_base2gripper, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_PARK);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_PARK : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_PARK" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_base2gripper, t_base2gripper, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_HORAUD);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_HORAUD : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_HORAUD" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_base2gripper, t_base2gripper, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_ANDREFF);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_ANDREFF : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_ANDREFF" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_base2gripper, t_base2gripper, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_DANIILIDIS);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_DANIILIDIS : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_DANIILIDIS" + std::to_string(image_counter) << TF_cam2base;
	}
	else if (calibration_type == CalibrationType::HAND_IN_EYE)
	{
		std::cout << "Hand in eye Calibration : " << std::endl;

		cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_TSAI);

		cv::Mat TF_cam2base;
		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_TSAI: TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_TSAI" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_PARK);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_PARK : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_PARK" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_HORAUD);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_HORAUD : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_HORAUD" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_ANDREFF);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_ANDREFF : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_ANDREFF" + std::to_string(image_counter) << TF_cam2base;

		cv::calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, R_cam2base, t_cam2base, cv::HandEyeCalibrationMethod::CALIB_HAND_EYE_DANIILIDIS);

		to_homogeneous_tf_matrix(R_cam2base, t_cam2base, TF_cam2base);
		std::cout << "CALIB_HAND_EYE_DANIILIDIS : TF_cam2base: " << TF_cam2base << std::endl;
		log_file << "CALIB_HAND_EYE_DANIILIDIS" + std::to_string(image_counter) << TF_cam2base;
	}
}

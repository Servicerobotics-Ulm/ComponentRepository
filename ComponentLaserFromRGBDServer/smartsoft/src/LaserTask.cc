//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain
// The SmartSoft Toolchain has been developed by:
//  
// Service Robotics Research Center
// University of Applied Sciences Ulm
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// www.servicerobotik-ulm.de
//
// This file is generated once. Modify this file to your needs. 
// If you want the toolchain to re-generate this file, please 
// delete it before running the code generator.
//--------------------------------------------------------------------------

//------------------------------------------------------------------------
//
//  Copyright (C) 2018 Nayabrasul Shaik, Matthias Lutz, Matthias Rollenhagen
//
//        shaik@hs-ulm.de, lutz@hs-ulm.de, rollenhagen@hs-ulm.de
//
//        Christian Schlegel (schlegel@hs-ulm.de)
//        University of Applied Sciences
//        Prittwitzstr. 10
//        89075 Ulm (Germany)
//
//  This file is part of the "SmartLaserFromRGBDServer component".
//
//  The method for converting 3D pointcloud to 2D laserscan is based on Mobile Robot Programming Toolkit (MRPT), http://www.mrpt.org/
//  https://github.com/MRPT/mrpt/blob/1371504fd3fdb891b92e80aa53eb26c4b33015cd/libs/obs/src/CObservation3DRangeScan.cpp
//--------------------------------------------------------------------------

//------------------------------------------------------------------------
//  For License : https://www.mrpt.org/License/
//  Copyright (c) 2005-2014, Individual contributors, see AUTHORS file
//  Copyright (c) 2005-2014, MAPIR group, University of Malaga
//  Copyright (c) 2012-2014, University of Almeria
//  All rights reserved.

//  Redistribution and use in source and binary forms, with or without
//  modification, are permitted provided that the following conditions are
//  met:
//  * Redistributions of source code must retain the above copyright
//        notice, this list of conditions and the following disclaimer.
//   * Redistributions in binary form must reproduce the above copyright
//        notice, this list of conditions and the following disclaimer in the
//        documentation and/or other materials provided with the distribution.
//   * Neither the name of the copyright holders nor the
//        names of its contributors may be used to endorse or promote products
//        derived from this software without specific prior written permission.

//  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
//  'AS IS' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
//  TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
//  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS BE LIABLE
//  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
//  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
//    SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
//  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
//  STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
//  ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
//  POSSIBILITY OF SUCH DAMAGE.
//--------------------------------------------------------------------------


#include "LaserTask.hh"
#include "ComponentLaserFromRGBDServer.hh"

#ifdef WITH_MRPT_2_0_VERSION
#include <mrpt/system/CTicTac.h>
#else
#include <mrpt/utils/CTicTac.h>
#endif

#include <EulerTransformationMatrices.hh>
//#include <Eigen/src/Core/Matrix.h>
//#include <Eigen/src/Core/MatrixBase.h>

#include <pcl/filters/passthrough.h>
#include <pcl/common/transforms.h>
#include <cmath>

#define STOP while (std::cin.get() != '\n');

#define DEGTORAD(x) x*M_PI/180.0f
#define RADTODEG(x) x*180.0f/M_PI

LaserTask::LaserTask(SmartACE::SmartComponent *comp)
:	LaserTaskCore(comp)
{
	first_image_flag =true;
}
LaserTask::~LaserTask() 
{
	std::cout << "destructor LaserTask\n";
}

int LaserTask::on_entry()
{

	ParameterStateStruct global_state = COMP->getGlobalState();
	min_dist = global_state.getLaser_generator().getMin_range();
    max_dist = global_state.getLaser_generator().getMax_range();
    vertical_view = global_state.getLaser_generator().getVertical_fov(); //  degrees of vertical view
    angle_resolution = DEGTORAD(global_state.getLaser_generator().getAngle_resolution()); // angular resolution
    robot_base_frame_height_from_floor = COMP->getGlobalState().getLaser_generator().getFloor_threshold_distance();

    sensor_pose_x = global_state.getScanner().getX();
    sensor_pose_y = global_state.getScanner().getY();
    sensor_pose_z = global_state.getScanner().getZ();
    sensor_pose_azimuth = global_state.getScanner().getAzimuth();
    sensor_pose_elevation = global_state.getScanner().getElevation();
    sensor_pose_roll = global_state.getScanner().getRoll();

	std::cout << "[LaserTask] Initializing ..." << std::endl;
	return 0;
}
int LaserTask::on_execute()
{
	// this method is called from an outside loop,
	// hence, NEVER use an infinite loop (like "while(1)") here inside!!!
	// also do not use blocking calls which do not result from smartsoft kernel

		// wait for scan (PushNewest)
		status = COMP->rgbdClient->getUpdateWait(rgbd_scan);

		if (status != Smart::SMART_OK) {

			std::cout << "blocking wait  status " << Smart::StatusCodeConversion(status) << " not ok => retry ..." << std::endl;
		}
		else
		{
			//Process RealSense Data
			if(true!=rgbd_scan.getIs_valid())
			{
				std::cout <<"RealSense Image data is INVALID" << std::endl;
			} else {

				if(first_image_flag)
				{
					read_intrinsics_extrinsics(rgbd_scan);
					init_laser_generation();
				}
				//Convert range image into 2D laser
				//realsense_to_laserscan(rgbd_scan, laser_scan);

				//set basestate
				CommBasicObjects::CommBaseState base_state = rgbd_scan.getBase_state();

				//std::cout<<"odom pose: "<<rgbd_scan.getBase_state().get_base_raw_position().get_x(1)<<" "
				//					                     <<rgbd_scan.getBase_state().get_base_raw_position().get_y(1)<<" "
				//					                     <<rgbd_scan.getBase_state().get_base_raw_position().get_base_azimuth()<<std::endl;


				laser_scan.setBase_state(base_state);
				CommBasicObjects::CommPose3d base_pose = base_state.getBasePose().getPose3D();



				CommBasicObjects::CommPose3d sensor_pose(rgbd_scan.getSensor_pose());
				//laser_scan.set_sensor_pose(sensor_pose);
				//laser_scan.set_sensor_pose(CommBasicObjects::CommPose3d(sensor_pose.get_x(),sensor_pose.get_y(),sensor_pose.get_z(),0,0,0));
				//publish the laser in robot base frame
				laser_scan.set_sensor_pose(CommBasicObjects::CommPose3d(sensor_pose_x, sensor_pose_y, sensor_pose_z,
																		sensor_pose_azimuth, sensor_pose_elevation, sensor_pose_roll));

				// set robot scanner position
				double x = sensor_pose.get_x();
				double y = sensor_pose.get_y();
				double z = sensor_pose.get_z();
				double azimuth = sensor_pose.get_azimuth();
				double elevation = sensor_pose.get_elevation();
				double roll = sensor_pose.get_roll();
				arma::mat mat_sensor;

				EulerTransformationMatrices::create_zyx_matrix(sensor_pose_x, sensor_pose_y, sensor_pose_z,
						                                       sensor_pose_azimuth, sensor_pose_elevation, sensor_pose_roll, mat_sensor);

				// set world scanner position
				double base_x = 0;
				double base_y = 0;
				double base_z = 0;
				double base_a = 0;
				arma::mat mat_base(4, 4);

				base_x = base_state.get_base_position().get_x();
				base_y = base_state.get_base_position().get_y();
				base_z = base_state.get_base_position().get_z();
				if (COMP->getGlobalState().getScanner().getOn_turret()) {
					//base_a = base_state.get_base_position().get_turret_alpha();
				} else {
					base_a = base_state.get_base_position().get_base_azimuth();
				}

				EulerTransformationMatrices::create_zyx_matrix(base_x, base_y, base_z, base_a, 0, 0, mat_base);
				arma::mat mat_world = mat_base * mat_sensor;
				CommBasicObjects::CommPose3d world_pose(mat_world);



//				double sensor_yaw = sensor_pose.get_azimuth(), sensor_pitch = sensor_pose.get_elevation(), sensor_roll = sensor_pose.get_roll();
//				double sensor_x = sensor_pose.getPosition().getX() / 1000, sensor_y = sensor_pose.getPosition().getY() / 1000, sensor_z = sensor_pose.getPosition().getZ() / 1000;
//
//				double bbase_yaw = base_pose.get_azimuth(), bbase_pitch = base_pose.get_elevation(), bbase_roll = base_pose.get_roll();
//				double bbase_x = base_pose.getPosition().getX() / 1000, bbase_y = base_pose.getPosition().getY() / 1000, bbase_z = base_pose.getPosition().getZ() / 1000;

				laser_scan.set_scanner_x(world_pose.get_x());
				laser_scan.set_scanner_y(world_pose.get_y());
				laser_scan.set_scanner_z(world_pose.get_z());

				laser_scan.set_scanner_azimuth(world_pose.get_azimuth());
				laser_scan.set_scanner_elevation(world_pose.get_elevation());
				laser_scan.set_scanner_roll(world_pose.get_roll());


				realsense_to_laserscan(rgbd_scan, laser_scan);


				Smart::StatusCode push_status = COMP->laserServiceOut->put(laser_scan);
				if (push_status != Smart::SMART_OK) {
					std::cerr << "[LaserTask] WARNING: error on push (" << Smart::StatusCodeConversion(push_status)
					<< ")" << std::endl;
				}

				// copy local scan to global scan
				SmartACE::SmartGuard scan_guard(COMP->ScanLock);
				COMP->global_scan = laser_scan;
				scan_guard.release();

				if (COMP->getGlobalState().getScanner().getVerbose())
				{
					const unsigned int index = laser_scan.get_scan_size();
					std::cout << "[LaserTask] Scan " << laser_scan.get_scan_update_count() << " sent." << " Scan Size " << index << "/"
					<< "Max Distance = " << laser_scan.get_max_distance() << "mm" << std::endl;

				}

			}
		}
			auto now = Smart::Clock::now();
			std::cout <<'\r'<<"Laser frequency = " <<1000.0f/std::chrono::duration_cast<std::chrono::milliseconds>(now -last).count()<< " Hz" <<std::flush;
			last = now;
	// it is possible to return != 0 (e.g. when the task detects errors), then the outer loop breaks and the task stops
	return 0;
}
int LaserTask::on_exit()
{
	std::cout << "[LaserTask] Exiting the task" << std::endl;
	// use this method to clean-up resources which are initialized in on_entry() and needs to be freed before the on_execute() can be called again
	return 0;
}


void LaserTask::createPointCloud(DomainVision::CommDepthImage &depth_image, pcl::PointCloud<pcl::PointXYZ>::Ptr point_cloud_out) {

	// get depth data
	DomainVision::DepthFormatType depth_format = depth_image.getFormat();
	uint32_t depth_width 							= depth_image.getWidth();
	uint32_t depth_height 							= depth_image.getHeight();



	for (uint32_t depth_row = 0; depth_row < depth_height; ++depth_row) { //along y
		for (uint32_t depth_col = 0; depth_col < depth_width; ++depth_col) { //along x-axis


			float depth_meters = get_depth(depth_image, depth_row, depth_col);

			//find x, y, z for given depth pixel in rgb frame
			float x_in_m, y_in_m, z_in_m;
			calcPointXYZ (depth_row, depth_col, depth_meters, x_in_m, y_in_m, z_in_m, depth_intrinsics, depth_to_color_extrinsics);


			if(std::isinf(x_in_m) || std::isinf(z_in_m) || std::isinf(y_in_m)){
				continue;
			}

			if(std::isnan(x_in_m) || std::isnan(z_in_m) || std::isnan(y_in_m)){
				continue;
			}

			if(x_in_m != x_in_m || y_in_m != y_in_m || z_in_m != z_in_m){
				continue;
			}
			point_cloud_out->points.push_back(pcl::PointXYZ(x_in_m, y_in_m, z_in_m));
		}
	}

}



void LaserTask::findMinimumDistances(const pcl::PointCloud<pcl::PointXYZ>::Ptr inputCloud, std::deque<float>& laser_ray_distances_out){

	std::map<int, double> angle_distances;
	std::map<int, pcl::PointXYZ> laser_points_min;

	for(pcl::PointCloud<pcl::PointXYZ>::const_iterator it=inputCloud->begin();it!=inputCloud->end();++it){

		double x = it->x, y = it->y;
		const double phi_wrt_origin = atan2(y, x);

		int i_range = fabs(pi_to_pi(phi_wrt_origin) - start_angle) / angle_resolution;

		if (i_range < 0 || i_range >= int(nLaserRays)){
			std::cout<<"[LaserTask] skipp point not within field of view";
			continue;
		}

		const double r_wrt_origin = sqrt(x*x + y*y)*1000;
		if(angle_distances.find(i_range) == angle_distances.end())
		{
			angle_distances.insert(std::make_pair(i_range, r_wrt_origin));

		}else if(angle_distances[i_range]>r_wrt_origin)
		{
			angle_distances[i_range] = r_wrt_origin;
			laser_points_min[i_range] = pcl::PointXYZ(x,y,0);
		}
	}

#ifdef HEW //WITH_PCL_VISUALIZATION
	pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_laser_min(new pcl::PointCloud<pcl::PointXYZ>);

	for(auto it=laser_points_min.begin();it!=laser_points_min.end();++it){
		cloud_laser_min->push_back(it->second);
	}

	COMP->visTask->showPointCloud(cloud_laser_min, "laserPoints", 255,255,0);
#endif

	laser_ray_distances_out.clear();

	//check if all the indexes are filled, if not fill the ray with value more than max_dist, it will be invalidated in comm object
	for (size_t i = 0; i < nLaserRays; i++) {
		if(angle_distances.find(i) != angle_distances.end())
		{
			laser_ray_distances_out.push_front(angle_distances[nLaserRays - 1 - i]);
		}else
		{
			laser_ray_distances_out.push_front(max_dist+1000);
		}
	}
}

/* +------------------------------------------------------------------------+
   |                     Mobile Robot Programming Toolkit (MRPT)            |
   |                          http://www.mrpt.org/                          |
   |                                                                        |
   | Copyright (c) 2005-2018, Individual contributors, see AUTHORS file     |
   | See: http://www.mrpt.org/Authors - All rights reserved.                |
   | Released under BSD License. See details in http://www.mrpt.org/License |
   +------------------------------------------------------------------------+ */
//	Based on MRPT library function "convertTo2DScan"
//	https://raw.githubusercontent.com/MRPT/mrpt/master/libs/obs/src/CObservation3DRangeScan.cpp
//  // Algorithm 2: project to 3D and reproject (for a different sensorPose at the origin)

bool LaserTask::realsense_to_laserscan(DomainVision::CommRGBDImage &rgbd_scan, CommBasicObjects::CommMobileLaserScan& laser_scan)
{

	DomainVision::CommDepthImage comm_depth_image = rgbd_scan.getDepth_image();

#ifdef WITH_MRPT_2_0_VERSION
	mrpt::system::CTicTac stopwatch;
#else
	mrpt::utils::CTicTac stopwatch;
#endif

	/////////////////////////////
	// 1. generate pointcloud (camera frame
	stopwatch.Tic();
	pcl::PointCloud<pcl::PointXYZ>::Ptr camera_point_cloud (new pcl::PointCloud<pcl::PointXYZ>());
	createPointCloud(comm_depth_image, camera_point_cloud);
#ifdef WITH_PCL_VISUALIZATION
	COMP->visTask->showPointCloud(camera_point_cloud, "cameraFramePointCloud", 0,0,255);
	double createPointCloud_time = stopwatch.Tac();
	std::cout << "[set_laser_ray_distances] createPointCloud time: " << createPointCloud_time << "s" << std::endl;
#endif


	/////////////////////////////
	// 2. transform pointcloud to robot frame
	stopwatch.Tic();
	pcl::PointCloud<pcl::PointXYZ>::Ptr robot_point_cloud (new pcl::PointCloud<pcl::PointXYZ>());
	CommBasicObjects::CommPose3d sensor_pose   = rgbd_scan.getSensor_pose();
	double sensor_yaw = sensor_pose.get_azimuth(), sensor_pitch = sensor_pose.get_elevation(), sensor_roll = sensor_pose.get_roll();
	Eigen::Affine3f transform = Eigen::Affine3f::Identity();
	transform = pcl::getTransformation (sensor_pose.getPosition().get_x(1), sensor_pose.getPosition().get_y(1), sensor_pose.getPosition().get_z(1),
			sensor_roll, sensor_pitch, sensor_yaw);

	pcl::transformPointCloud(*camera_point_cloud,*robot_point_cloud,transform);
#ifdef WITH_PCL_VISUALIZATION
	COMP->visTask->showPointCloud(robot_point_cloud, "robotFramePointCloud", 255,0,0);
	double transformPointCloud = stopwatch.Tac();
	std::cout << "[set_laser_ray_distances] transformPointCloud time: " << transformPointCloud << "s" << std::endl;
#endif

	/////////////////////////////
	// 3. remove floor
	stopwatch.Tic();
	pcl::PointCloud<pcl::PointXYZ>::Ptr cloud_filtered_z(new pcl::PointCloud<pcl::PointXYZ>);
	pcl::PassThrough<pcl::PointXYZ> pass_z;
	pass_z.setInputCloud(robot_point_cloud);
	pass_z.setFilterFieldName("z");
	pass_z.setFilterLimits(robot_base_frame_height_from_floor+0.02,std::numeric_limits<float>::max());
	pass_z.filter(*cloud_filtered_z);
#ifdef WITH_PCL_VISUALIZATION
	COMP->visTask->showPointCloud(cloud_filtered_z, "robotFramePointCloud_filtered", 0,255,0);
	double filter = stopwatch.Tac();
	std::cout << "[set_laser_ray_distances] filter time: " << filter << "s" << std::endl;
#endif

	/////////////////////////////
	// 5. find min + downproject (also covert to polar system (dist + angl))
	stopwatch.Tic();
	findMinimumDistances(cloud_filtered_z,laser_ray_distances);
#ifdef WITH_PCL_VISUALIZATION
	double findMinimumDistances = stopwatch.Tac();
	std::cout << "[set_laser_ray_distances] filter findMinimumDistances: " << findMinimumDistances << "s" << std::endl;
#endif



	/////////////////////////////
	// 6. fill the comobject
	stopwatch.Tic();
	// set scan header
	laser_scan.set_scan_time_stamp(CommBasicObjects::CommTimeStamp::now());
	laser_scan.set_scan_update_count(rgbd_scan.getSeq_count());
	laser_scan.set_scan_length_unit(1.0);
	laser_scan.set_scan_double_field_of_view(RADTODEG(start_angle), RADTODEG(angle_resolution));
	laser_scan.set_max_distance(max_dist); //in mm
	laser_scan.set_min_distance(min_dist); //in mm
	laser_scan.set_scan_valid(true);

	set_laser_ray_distances(laser_scan,laser_ray_distances);

#ifdef WITH_PCL_VISUALIZATION
	pcl::PointCloud<pcl::PointXYZ>::Ptr commlasercloud(new pcl::PointCloud<pcl::PointXYZ>);
	double set_laser_ray_distances = stopwatch.Tac();
	std::cout << "[set_laser_ray_distances] filter set_laser_ray_distances: " << set_laser_ray_distances << "s" << std::endl;

	for(unsigned int i=0; i<nLaserRays;++i){
		double x,y,z;
		laser_scan.get_scan_cartesian_3dpoint_robot(i,x,y,z,1.0);
		commlasercloud->push_back(pcl::PointXYZ(x,y,z));
	}

	COMP->visTask->showPointCloud(commlasercloud, "commlasercloud", 255,0,255);
#endif

	return true;

}

void LaserTask::init_laser_generation()
{
	// do these calculation only once
	//These view angle calculations are from realsense library
	hfov_rad = std::atan2(depth_intrinsics.cx + 0.5f, depth_intrinsics.fx) + std::atan2(depth_intrinsics.cols - (depth_intrinsics.cx + 0.5f), depth_intrinsics.fx);
	vfov_rad = std::atan2(depth_intrinsics.cy + 0.5f, depth_intrinsics.fy) + std::atan2(depth_intrinsics.rows - (depth_intrinsics.cy + 0.5f), depth_intrinsics.fy);

	//round off horizontal view to multiple of angle_resolution
	hfov_rad = hfov_rad-fmod(hfov_rad,angle_resolution);

	nLaserRays         = ceil(1 + (hfov_rad/angle_resolution));
	start_angle        = -0.5f*hfov_rad;
	vertical_view      = vfov_rad*2.0f; // consider all the vertical fov
	depth_data_type    = rgbd_scan.getDepth_image().getFormat();
	first_image_flag   = false;

	display_parameters();
}

double LaserTask::pi_to_pi(double angle) {
	angle += M_PI;
	double ret_angle = fmod(angle, 2* M_PI );

	if (angle < 0)
		ret_angle += 2* M_PI ;

	ret_angle -= M_PI;

	return ret_angle;
}

void LaserTask::display_parameters()
{
	    std::cout <<"-----------------------------------------------------------------"<<std::endl;
		std::cout <<std::setw(40)<<"Laser Parameters"<<std::endl;
		std::cout <<"-----------------------------------------------------------------"<<std::endl;
		std::cout <<std::setw(25)<<  "Number of rays"    <<" = " << nLaserRays<<std::endl;
		std::cout <<std::setw(25)<<  "Horizontal Field of View"  <<" = " << RADTODEG(hfov_rad)<< " degrees"<<std::endl;
		std::cout <<std::setw(25)<<  "Vertical Field of View"  <<" = " << RADTODEG(vfov_rad)<< " degrees"<<std::endl;
		std::cout <<std::setw(25)<<  "Angle resolution"  <<" = " << RADTODEG(angle_resolution)<< " degrees"<<std::endl;
		std::cout <<std::setw(25)<<  "Start_angle"       <<" = " << RADTODEG(start_angle) <<std::endl;
		std::cout <<std::setw(25)<<  "Max distance"      <<" = " << max_dist/1000.0<< " meters"<<std::endl;
		std::cout <<std::setw(25)<<  "Min distance"      <<" = " << min_dist/1000.0<< " meters"<<std::endl;
		std::cout <<std::setw(25)<<  "Floor distance from Robot base frame"    <<" = " << robot_base_frame_height_from_floor<< " meters"<<std::endl;
		std::cout <<"-----------------------------------------------------------------"<<std::endl;
}

/*Convert image pixel to real world point
 * equations and functions are similar to realsense library
 * https://github.com/IntelRealSense/librealsense/blob/master/include/librealsense2/rsutil.h
 *
 * */
void LaserTask::deproject(const st_intrinsics& intrinsics, const uint32_t& r, const uint32_t& c, const float &depth_val_meters, float &out_x, float &out_y, float &out_z)
{
	float x = (c - intrinsics.cx) / intrinsics.fx;
	float y = (r - intrinsics.cy) / intrinsics.fy;
	if(intrinsics.distortion_model == DomainVision::ImageDistortionModel::BROWN_CONRADY)
	{
		float r2  = x*x + y*y;
		float f =    1 + intrinsics.distortion_coeffs[0]*r2    + intrinsics.distortion_coeffs[1]*r2*r2 + intrinsics.distortion_coeffs[4]*r2*r2*r2;
		float ux = x*f + 2*intrinsics.distortion_coeffs[2]*x*y + intrinsics.distortion_coeffs[3]*(r2 + 2*x*x);
		float uy = y*f + 2*intrinsics.distortion_coeffs[3]*x*y + intrinsics.distortion_coeffs[2]*(r2 + 2*y*y);
		x = ux;
		y = uy;
		//std::cout << "distortion in de projection" <<std::endl;
	}
	out_x = depth_val_meters * x;
	out_y = depth_val_meters * y;
	out_z = depth_val_meters;

}
/*Convert real world point to image pixel*/
void LaserTask::project(const st_intrinsics& intrinsics, uint32_t& out_r, uint32_t& out_c, const float &in_x, const float &in_y, const float &in_z)
{

	float x = in_x/in_z;
	float y = in_y/in_z;


	if(intrinsics.distortion_model == DomainVision::ImageDistortionModel::BROWN_CONRADY)
	{
		float r2  = x*x + y*y;
		float f = 1 + intrinsics.distortion_coeffs[0]*r2 + intrinsics.distortion_coeffs[1]*r2*r2 + intrinsics.distortion_coeffs[4]*r2*r2*r2;
		x *= f;
		y *= f;
		float dx = x + 2*intrinsics.distortion_coeffs[2]*x*y + intrinsics.distortion_coeffs[3]*(r2 + 2*x*x);
		float dy = y + 2*intrinsics.distortion_coeffs[3]*x*y + intrinsics.distortion_coeffs[2]*(r2 + 2*y*y);
		x = dx;
		y = dy;
	}

	out_c =  x * intrinsics.fx + intrinsics.cx;
    out_r =  y * intrinsics.fy + intrinsics.cy;
}

void LaserTask::transform (const st_extrinsics& extrinsics, float &x, float &y, float &z)
{

	float from_point_x = x;
	float from_point_y = y;
	float from_point_z = z;


	float to_point_x = extrinsics.rotation[0] * from_point_x + extrinsics.rotation[3] * from_point_x + extrinsics.rotation[6] * from_point_x + extrinsics.translation[0];
	float to_point_y = extrinsics.rotation[1] * from_point_y + extrinsics.rotation[4] * from_point_y + extrinsics.rotation[7] * from_point_y + extrinsics.translation[1];
	float to_point_z = extrinsics.rotation[2] * from_point_z + extrinsics.rotation[5] * from_point_z + extrinsics.rotation[8] * from_point_z + extrinsics.translation[2];

	x= to_point_x;
	y= to_point_y;
	z= to_point_z;

	//std::cout <<"from: " <<from_point_x <<", "<<from_point_y <<", "<<from_point_z <<", "<<"   To: " <<to_point_x <<", "<<to_point_y <<", "<<to_point_z <<", "<<std::endl;

}

void LaserTask::calcPointXYZ (const uint32_t& r, const uint32_t& c, const float &depth_val_meters, float &x, float &y, float &z,
		                             const st_intrinsics& intrinsics, const st_extrinsics& extrinsics)
{

  //depth value is not valid
  if(std::isnan(depth_val_meters) || depth_val_meters <= 0.001)
  {
    //depth value is not valid
	const float bad_point = std::numeric_limits<float>::quiet_NaN();
    x = y = z = bad_point;
  }
  else
  {
	  // find the corresponding x,y,z of given depth pixel in depth frame
	  deproject(intrinsics,r, c, depth_val_meters, x, y, z);
	  // transform x,y,z into rgb coordinate system using extrinsics
	  // sensor pose is transform between robot base frame and depth origin, so transform to RGB camera frame is not required
	  //transform(extrinsics, x, y, z);
  }
}

void LaserTask::read_intrinsics_extrinsics(const DomainVision::CommRGBDImage& rgbd_image)
{
	// get color intrinsics
	{
	DomainVision::CommVideoImage comm_rgb_image = rgbd_image.getColor_image();
	arma::mat comm_color_intrinsic = arma::zeros(4,4);
	comm_color_intrinsic = comm_rgb_image.get_intrinsic();

	color_intrinsics.fx 	= comm_color_intrinsic(0,0);
	color_intrinsics.fy 	= comm_color_intrinsic(1,1);
	color_intrinsics.cx 	= comm_color_intrinsic(0,2);
	color_intrinsics.cy 	= comm_color_intrinsic(1,2);
	color_intrinsics.cols 	= comm_rgb_image.getParameter().width;
	color_intrinsics.rows 	= comm_rgb_image.getParameter().height;
	color_intrinsics.distortion_model = comm_rgb_image.getDistortion_model();

	arma::mat comm_color_distortion = arma::zeros(1,5);

	comm_color_distortion = comm_rgb_image.get_distortion();
	color_intrinsics.distortion_coeffs[0] = comm_color_distortion(0,0);
	color_intrinsics.distortion_coeffs[1] = comm_color_distortion(0,1);
	color_intrinsics.distortion_coeffs[2] = comm_color_distortion(0,2);
	color_intrinsics.distortion_coeffs[3] = comm_color_distortion(0,3);
	color_intrinsics.distortion_coeffs[4] = comm_color_distortion(0,4);
	}

	// get depth intrinsics
	{

	DomainVision::CommDepthImage comm_depth_image = rgbd_image.getDepth_image();

	arma::mat comm_depth_intrinsic = arma::zeros(4,4);
	comm_depth_intrinsic = comm_depth_image.get_intrinsic();

	depth_intrinsics.fx 	= comm_depth_intrinsic(0,0);
	depth_intrinsics.fy 	= comm_depth_intrinsic(1,1);
	depth_intrinsics.cx 	= comm_depth_intrinsic(0,2);
	depth_intrinsics.cy 	= comm_depth_intrinsic(1,2);
	depth_intrinsics.cols 	= comm_depth_image.getWidth();
	depth_intrinsics.rows 	= comm_depth_image.getHeight();
	depth_intrinsics.distortion_model = comm_depth_image.getDistortion_model();

	arma::mat comm_depth_distortion = arma::zeros(1,5);

	comm_depth_distortion = comm_depth_image.get_distortion();
	depth_intrinsics.distortion_coeffs[0] = comm_depth_distortion(0,0);
	depth_intrinsics.distortion_coeffs[1] = comm_depth_distortion(0,1);
	depth_intrinsics.distortion_coeffs[2] = comm_depth_distortion(0,2);
	depth_intrinsics.distortion_coeffs[3] = comm_depth_distortion(0,3);
	depth_intrinsics.distortion_coeffs[4] = comm_depth_distortion(0,4);

    //get depth extrinsics
	arma::mat comm_depth_extrinsics = arma::zeros(1,12);
	comm_depth_extrinsics = comm_depth_image.get_extrinsic();

	depth_to_color_extrinsics.rotation[0] =     comm_depth_extrinsics(0,0);
	depth_to_color_extrinsics.rotation[1] =     comm_depth_extrinsics(0,1);
	depth_to_color_extrinsics.rotation[2] =     comm_depth_extrinsics(0,2);
	depth_to_color_extrinsics.rotation[3] =     comm_depth_extrinsics(0,3);
	depth_to_color_extrinsics.rotation[4] =     comm_depth_extrinsics(0,4);
	depth_to_color_extrinsics.rotation[5] =     comm_depth_extrinsics(0,5);
	depth_to_color_extrinsics.rotation[6] =     comm_depth_extrinsics(0,6);
	depth_to_color_extrinsics.rotation[7] =     comm_depth_extrinsics(0,7);
	depth_to_color_extrinsics.rotation[8] =     comm_depth_extrinsics(0,8);

	depth_to_color_extrinsics.translation[0] = comm_depth_extrinsics(0,9);
	depth_to_color_extrinsics.translation[1] = comm_depth_extrinsics(0,10);
	depth_to_color_extrinsics.translation[2] = comm_depth_extrinsics(0,11);
	}

}

inline float LaserTask::get_depth(DomainVision::CommDepthImage& comm_depth_image, int row, int col)
{
	float current_distance_meters;

	if (depth_data_type == DomainVision::DepthFormatType::UINT16) {

		const uint16_t pixel = comm_depth_image.get_distance < uint16_t	> (col, row);
		current_distance_meters = pixel / 1000.0f;

	} else if (depth_data_type == DomainVision::DepthFormatType::FLOAT) {

		float pixel = comm_depth_image.get_distance<float>(col, row);

		current_distance_meters = pixel; //1000.0f;

	}

	return current_distance_meters;
}

void LaserTask::set_laser_ray_distances(CommBasicObjects::CommMobileLaserScan& laser_scan, std::deque<float>& laser_ray_distances)
{

	const int desiredScans = 1 + hfov_rad / angle_resolution;
	const int rangerScans = 1 + hfov_rad / angle_resolution;

	laser_scan.set_max_scan_size(desiredScans);


	const int firstScanIndex = ((rangerScans - desiredScans) * 0.5);

	int lastScanIndex = rangerScans - firstScanIndex;

	uint32_t num_valid_points = 0;
	for (int i = firstScanIndex; i < lastScanIndex; ++i) {
		const unsigned int dist = laser_ray_distances.at(i);
		if (dist >= min_dist && dist <= max_dist) {
			++num_valid_points;
		}
	}

	laser_scan.set_scan_size(num_valid_points);

	uint32_t valid_point_index = 0;
	for (int i = firstScanIndex; i < lastScanIndex; ++i) {
		const unsigned int dist = laser_ray_distances.at(i);
		if (dist >= min_dist && dist <= max_dist) {
			laser_scan.set_scan_index(valid_point_index, i - firstScanIndex);
			laser_scan.set_scan_integer_distance(valid_point_index, dist);
			++valid_point_index;
		}
	}
	laser_scan.set_scan_valid(true);
}

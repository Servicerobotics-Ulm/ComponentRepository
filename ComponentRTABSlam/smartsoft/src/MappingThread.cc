//--------------------------------------------------------------------------
// Code generated by the SmartSoft MDSD Toolchain
// The SmartSoft Toolchain has been developed by:
//  
// Service Robotics Research Center
// University of Applied Sciences Ulm
// Prittwitzstr. 10
// 89075 Ulm (Germany)
//
// Information about the SmartSoft MDSD Toolchain is available at:
// www.servicerobotik-ulm.de
//
// This file is generated once. Modify this file to your needs. 
// If you want the toolchain to re-generate this file, please 
// delete it before running the code generator.
//--------------------------------------------------------------------------
// --------------------------------------------------------------------------
//
//  Copyright (C) 2018 Nayabrasul Shaik
//
//        shaik@hs-ulm.de
//
//        ZAFH Servicerobotik Ulm
//        University of Applied Sciences
//        Prittwitzstr. 10
//        D-89075 Ulm
//        Germany
//
//  This library is free software; you can redistribute it and/or
//  modify it under the terms of the GNU Lesser General Public
//  License as published by the Free Software Foundation; either
//  version 2.1 of the License, or (at your option) any later version.
//
//  This library is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
//  Lesser General Public License for more details.
//
//  You should have received a copy of the GNU Lesser General Public
//  License along with this library; if not, write to the Free Software
//  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
//
// --------------------------------------------------------------------------
#include "MappingThread.hh"
#include "ComponentRTABSlam.hh"

#include "SmartSoft2RtabMapConverter.hh"
#include "CommBasicObjects/CommPose3d.hh"

#include <rtabmap/core/util3d.h>
#include <rtabmap/core/util2d.h>
#include <rtabmap/core/SensorData.h>
#include <rtabmap/core/CameraModel.h>
#include <rtabmap/utilite/ULogger.h>
#include <rtabmap/utilite/UConversion.h>
#include <rtabmap/utilite/UStl.h>

#include <rtabmap/utilite/UConversion.h>
#include <rtabmap/utilite/ULogger.h>
#include <rtabmap/utilite/UStl.h>
#include <rtabmap/utilite/UFile.h>
//#include <mrpt/poses/CPose3D.h>
//#include <mrpt/math.h>
//#include <mrpt/gui.h>
#include <cassert>
#include <chrono>
#include <thread>
#include <cstdio>



#include<vector>
#include <iostream>

MappingThread::MappingThread(SmartACE::SmartComponent *comp) 
:	MappingThreadCore(comp), OdomType_(Odomtype::VisualOdom)
{
	std::cout << "constructor MappingThread"<<std::endl;
	//smartodom_.onInit();

	ULogger::setType(ULogger::kTypeConsole);
	ULogger::setLevel(ULogger::kError);
}
MappingThread::~MappingThread() 
{
	std::cout << "destructor MappingThread\n";
}



int MappingThread::on_entry()
{
	//Initialize rtabmap
		rtabmap::ParametersMap parameters;
		std::string databasePath;

		bool IsMultisession = COMP->getGlobalState().getConfigureSLAM().getMultiSession();
		if(!IsMultisession)
		{

			std::stringstream date_string;
			date_string << static_cast<unsigned long>(::time(0));
			//make db name using current time stamp
			databasePath = UDirectory::homeDir() + "/rtabmap"+ date_string.str() + ".db";
		    std::cout << "db path = " << databasePath <<std::endl;

		}

		//rtabmap.init(parameters, databasePath);
		rtabmap.init(parameters,databasePath);

		int argc =0;
		char **argv = NULL;
	    app = new QApplication(argc, argv);
	    mapBuilder = new MapBuilder();

	    mapBuilder->show();
	    QApplication::processEvents();


	    // Read from parameter what kind of Odometry should be used
	    int Odom = COMP->getGlobalState().getConfigureSLAM().getOdomtype();
	    if(Odom ==0)
	    {
	    	OdomType_ = Odomtype::VisualOdom;
	    	std::cout << "Odometry used : Visual Odometry" <<std::endl;
	    }
	    else if(Odom ==1)
	    {
	    	OdomType_ = Odomtype::WheelOdom;
	    	std::cout << "Odometry used : Wheel Odometry" <<std::endl;
	    }

		return 0;
}
int MappingThread::on_execute()
{
	try {

		status = COMP->stateSlave->acquire("nonneutral");

		if (status == Smart::SMART_OK)
		{

			// wait for scan (PushNewest)
			status = COMP->rgbd_client->getUpdateWait(scan);
			if (status != Smart::SMART_OK) {

				std::cout << "blocking wait  status " << Smart::StatusCodeConversion(status) << " not ok => retry ..." << std::endl;
			}
			else
			{
				//Process RealSense Data
				if(true!=scan.getIs_valid())
				{
					std::cout <<"RGBD Image data is INVALID" << std::endl;
				}else{
					DomainVision::CommVideoImage comm_rgb_image   = scan.getColor_image();
					DomainVision::CommDepthImage comm_depth_image = scan.getDepth_image();

					CommBasicObjects::CommPose3d sensor_pose = scan.getSensor_pose();
					CommBasicObjects::CommPose3d base_pose = scan.getBase_state().get_base_position().get_base_pose3d();

					uint32_t rgb_frame_num = comm_rgb_image.getSeq_count();
					uint32_t depth_frame_num = comm_depth_image.getSeq_count();

					std::stringstream framenums;
					if(rgb_frame_num == depth_frame_num)
						framenums <<"RGB Frame Num: "<<rgb_frame_num <<", Depth Frame Num: "<<depth_frame_num;
					else
						framenums <<"?RGB Frame Num: "<<rgb_frame_num <<", ?Depth Frame Num: "<<depth_frame_num;

					//CHS::SmartGuard guard(COMP->rs_tracking_Mutex);
					//if(!first_image_flag)
						//init_person_tracking();

					//create sample from both images

					cv::Mat rgb_mat(comm_rgb_image.get_height(), comm_rgb_image.get_width(), CV_8UC3);
					cv::Mat depth_mat(comm_depth_image.getHeight(), comm_depth_image.getWidth(), CV_16UC1);

					/*---------------------------------------------------------------------------------------------------------------------------------------------*/
					// copy rgb data into mat
					{
						const unsigned char* imageData = comm_rgb_image.get_data();
						for (int r = 0; r < rgb_mat.rows; r++)
						{
							for (int c = 0; c < rgb_mat.cols; c++)
							{
								const unsigned char* pixel = (imageData + r * 3* rgb_mat.cols + c * 3);

								rgb_mat.at<cv::Vec3b>(r,c)[0]=pixel[2];
								rgb_mat.at<cv::Vec3b>(r,c)[1]=pixel[1];
								rgb_mat.at<cv::Vec3b>(r,c)[2]=pixel[0];
							}
						}
					}
					/*---------------------------------------------------------------------------------------------------------------------------------------------*/

					// copy distance data into mat
					{

						const uint16_t* depth_data_uint16;
						const float* depth_data_float;
						DomainVision::DepthFormatType depth_format = comm_depth_image.getFormat();
						if(depth_format==DomainVision::DepthFormatType::UINT16)
						{
							//depth_data_uint16 = comm_depth_image.get_distances_data<const uint16_t*>();
							depth_data_uint16 = comm_depth_image.get_distances_uint16();

						} else if (depth_format==DomainVision::DepthFormatType::FLOAT)
						{
							depth_data_float = comm_depth_image.get_distances_float();

						}


						for (uint32_t depth_row = 0; depth_row < depth_mat.rows; ++depth_row) {//along y
							for (uint32_t depth_col = 0; depth_col < depth_mat.cols;++depth_col) {//along x-axis

								if(depth_format==DomainVision::DepthFormatType::UINT16)
								{
									const uint16_t pixel = *(depth_data_uint16 + depth_row * depth_mat.cols + depth_col);
									depth_mat.at<uint16_t>(depth_row, depth_col)=pixel;
								} else if (depth_format==DomainVision::DepthFormatType::FLOAT)
								{
									const float pixel = *(depth_data_float + depth_row * depth_mat.cols + depth_col);
									depth_mat.at<uint16_t>(depth_row, depth_col)=static_cast<uint16_t>(pixel*1000); // realsense requires uint16_t format with distance in mm
								}
							}
						}

					}
					/*---------------------------------------------------------------------------------------------------------------------------------------------*/

					//ASSERTMSG_(((depth_mat.cols = rgb_mat.cols) && (depth_mat.rows = rgb_mat.rows)), "Size of RGB and Depth image are not same");


					double current_time = 0;//

					// localTransform is transform between Robot base and camera
					//rtabmap::Transform localTransform = transformFromSmartSoft(sensor_pose);
					rtabmap::Transform localTransform(0, 0, 1, 0,
							                         -1, 0, 0, 0,
							                          0,-1, 0, 0);

					rtabmap::CameraModel curr_cam_model(cameraModelFromSmartSoft(scan, localTransform));
					//rtabmap::SensorData data(rgb_mat, depth_mat, curr_cam_model, scan.get_rs_seq_count_rgb(), current_time);

					rtabmap::SensorData data(rgb_mat, depth_mat, curr_cam_model, 0, current_time);

					//std::cout << "current rgbd frame num =" << scan.get_rs_seq_count_rgb()<<std::endl;
					//std::cout << "SensorData  data.stamp() =" << data.stamp()<<std::endl;

					//smartodom_.processData(data, current_time);
					if(mapBuilder->isVisible())
					{
						rtabmap::Transform pose;
						rtabmap::OdometryInfo info;

					if(OdomType_ == Odomtype::VisualOdom)
					{
						pose = Odomfm.process(data, &info);

					}
					else if(OdomType_==Odomtype::WheelOdom)
					{

						CommBasicObjects::CommBasePose Odom_pose = scan.getBase_state().get_base_raw_position();
						pose = transformFromSmartSoftBasePose(Odom_pose);
					}


					if(rtabmap.process(data, pose))
					{

						mapBuilder->processStatistics(rtabmap.getStatistics());
						if(rtabmap.getLoopClosureId() > 0)
						{
							printf("Loop closure detected!\n");
						}
					}

					mapBuilder->processOdometry(data, pose, info);

					QApplication::processEvents();

					while(mapBuilder->isPaused() && mapBuilder->isVisible())
					{
						std::this_thread::sleep_for (std::chrono::milliseconds(10));
						QApplication::processEvents();
					}
					}

				}// Valid Data in the scan received


			}
		} // state
		status = COMP->stateSlave->release("nonneutral");



	}
	catch (std::exception &e)
	{
		std::cout << "exception: " << e.what() << std::endl;
	}

	return 0;
}
void MappingThread::init_odometry()
{

	rtabmap::Transform initialPose = rtabmap::Transform::getIdentity();


}
/**
 * @brief Method to convert char* to wchar_t*?
 * implementation from https://stackoverflow.com/a/8032108/1595504
 */
const wchar_t *MappingThread::GetWC(const char *c)
{
	const size_t cSize = strlen(c)+1;
	wchar_t* wc = new wchar_t[cSize];
	mbstowcs (wc, c, cSize);

	return wc;
}

/**
 * @brief Release the sample_set after processing.
 */
void MappingThread::release_images()
{


}

bool MappingThread::startStopTracking(bool isStart, int personId)
{
 return true;
}

int MappingThread::on_exit()
{
	// use this method to clean-up resources which are initialized in on_entry() and needs to be freed before the on_execute() can be called again

	std::cout << "Exiting MappingThread" <<std::endl;
	delete mapBuilder;
	delete app;

	return 0;
}
